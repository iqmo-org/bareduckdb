name: Sanitizer Testing (TSAN/ASAN)

on:
  # push:
  workflow_dispatch:

jobs:
  sanitizers:
    name: 'Sanitizer Tests - ${{ matrix.sanitizer }}'
    runs-on: ubuntu-latest
    #self-hosted

    permissions:
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
          - sanitizer: 'TSAN'
            docker-image: 'ghcr.io/nascheme/cpython-tsan:3.14t'
            sanitizer-env: 'TSAN_OPTIONS=halt_on_error=1'
          - sanitizer: 'ASAN'
            docker-image: 'ghcr.io/nascheme/cpython-asan:3.14t'
            sanitizer-env: 'ASAN_OPTIONS=allocator_may_return_null=1:halt_on_error=1:detect_leaks=1:detect_stack_use_after_return=1:check_initialization_order=1:strict_string_checks=1:detect_invalid_pointer_pairs=2:symbolize=1:fast_unwind_on_malloc=0'

    steps:
      - name: Checkout code
        uses: actions/checkout@main
        with:
          fetch-depth: 0
          submodules: true

      - name: Run ${{ matrix.sanitizer }} tests in Docker
        shell: bash
        run: |
          echo "Pre-Docker Debugging"
          echo "github.workspace: ${{ github.workspace }}"
          echo "GITHUB_WORKSPACE: $GITHUB_WORKSPACE"
          echo "PWD: $(pwd)"
          echo "Contents of PWD:"
          ls -la "$(pwd)" | head -30
          echo "Contents of github.workspace:"
          ls -la "${{ github.workspace }}" | head -30
          echo "Checking for critical files in PWD:"
          ls -l "$(pwd)/setup.py" "$(pwd)/pyproject.toml" 2>&1 || echo "Files missing in PWD!"
          echo "Checking for critical files in github.workspace:"
          ls -l "${{ github.workspace }}/setup.py" "${{ github.workspace }}/pyproject.toml" 2>&1 || echo "Files missing in github.workspace!"

          # Use PWD instead of github.workspace for self-hosted runners
          WORKSPACE_PATH="$(pwd)"
          echo "Using WORKSPACE_PATH: $WORKSPACE_PATH"

          # Pull latest version of the TSAN image
          echo "Pulling latest ${{ matrix.docker-image }}"
          docker pull ${{ matrix.docker-image }}

          # Create container and copy files instead of using volume mount
          # Volume mounts can be problematic with self-hosted runners
          CONTAINER_ID=$(docker create \
            --cap-add=SYS_PTRACE \
            --security-opt seccomp=unconfined \
            -w /workspace \
            ${{ matrix.docker-image }} \
            sleep infinity)

          echo "Created container: $CONTAINER_ID"

          # Start the container
          docker start "$CONTAINER_ID"

          # Copy all files from workspace into container
          echo "Copying files from $WORKSPACE_PATH to container:/workspace"
          docker cp "$WORKSPACE_PATH/." "$CONTAINER_ID:/workspace/"

          # Verify files were copied
          echo "Verifying files in container:"
          docker exec "$CONTAINER_ID" ls -la /workspace/ | head -30

          # Run the actual commands
          docker exec "$CONTAINER_ID" bash -c "
              set -e

              echo 'Environment Setup'
              echo 'Current directory:'
              pwd
              echo 'Contents of /workspace:'
              ls -la /workspace/ | head -30
              echo 'Verifying critical files:'
              ls -l /workspace/setup.py /workspace/pyproject.toml 2>&1 || echo 'Some files missing!'

              echo 'Installing system dependencies'
              apt-get update -qq
              apt-get install -y -qq unzip curl gcc g++ make clang gdb

              # Enable core dumps for debugging crashes
              ulimit -c unlimited
              echo '/tmp/core.%e.%p' > /proc/sys/kernel/core_pattern 2>/dev/null || echo 'Note: Could not set core_pattern (read-only in container), continuing anyway'

              # Combine all TSAN suppression files (CPython, NumPy, etc.)
              # Note: We disable deadlock detection during build to avoid the 128-lock limit
              # We also redirect TSAN reports to a file to prevent UV from treating them as build errors
              # Both will be re-enabled later for actual test execution
              if [ '${{ matrix.sanitizer }}' = 'TSAN' ]; then
                if [ -d /work/tsan_suppressions ]; then
                  echo 'Combining TSAN suppression files...'
                  cat /work/tsan_suppressions/*.txt > /tmp/combined_suppressions.txt
                  export TSAN_OPTIONS=\"halt_on_error=1:detect_deadlocks=0:log_path=/tmp/tsan_build.log:suppressions=/tmp/combined_suppressions.txt\"
                  echo \"TSAN_OPTIONS set to: \$TSAN_OPTIONS\"
                  echo \"Loaded suppressions from:\"
                  ls -la /work/tsan_suppressions/
                else
                  echo 'Warning: No suppression files found, using default TSAN options'
                  export TSAN_OPTIONS=\"halt_on_error=1:detect_deadlocks=0:log_path=/tmp/tsan_build.log\"
                  echo \"TSAN_OPTIONS set to: \$TSAN_OPTIONS\"
                fi
              else
                # For ASAN, disable leak detection initially to allow build/install
                export ASAN_OPTIONS='allocator_may_return_null=1:halt_on_error=1:detect_leaks=0'
              fi

              # Use debug mode for better sanitizer compatibility
              # - Disables LTO which can interfere with sanitizers
              # - Uses -O0 instead of -O3 for more reliable detection
              # - Enables bounds checking and other safety features
              export BAREDUCKDB_OPTIMIZATION=debug

              # Add sanitizer flags to compilation
              if [ '${{ matrix.sanitizer }}' = 'TSAN' ]; then
                export CFLAGS=\"-fsanitize=thread -fno-omit-frame-pointer -g \$CFLAGS\"
                export CXXFLAGS=\"-fsanitize=thread -fno-omit-frame-pointer -g \$CXXFLAGS\"
                export LDFLAGS=\"-fsanitize=thread \$LDFLAGS\"
              else
                export CFLAGS=\"-fsanitize=address -fno-omit-frame-pointer -g \$CFLAGS\"
                export CXXFLAGS=\"-fsanitize=address -fno-omit-frame-pointer -g \$CXXFLAGS\"
                # Use default ASAN runtime (same as Python) instead of -shared-libasan
                export LDFLAGS=\"-fsanitize=address \$LDFLAGS\"
              fi

              echo 'Python version:'
              python --version
              PYTHON_PATH=\$(which python)
              echo \"Using Python at: \$PYTHON_PATH\"

              echo 'Installing UV'
              curl -LsSf https://astral.sh/uv/install.sh | sh
              export PATH=\"\$HOME/.local/bin:\$PATH\"

              echo 'Installing build dependencies (including pyarrow for setup.py)'
              uv pip install --python \"\$PYTHON_PATH\" --system --break-system-packages --upgrade pip
              uv pip install --python \"\$PYTHON_PATH\" --system --break-system-packages \"setuptools>=64\" \"setuptools-scm>=8\" wheel cython \"packaging>=24.2\" pyarrow

              echo 'Cleaning any previous builds to ensure sanitizer flags are used'
              rm -rf build/ src/bareduckdb/core/impl/*.so .venv

              echo 'Installing bareduckdb and dependencies with uv sync'
              # For TSAN, force UV to use Python 3.14t which has TSAN symbols exported
              if [ '${{ matrix.sanitizer }}' = 'TSAN' ]; then
                echo 'Using Python 3.14t for TSAN compatibility'
                uv sync --no-dev --no-cache --python /work/.pyenv/versions/3.14.1t/bin/python3.14 -v
              else
                uv sync --no-dev --no-cache -v
              fi

              # Verify import works
              if ! python -c 'import bareduckdb; print(\"bareduckdb version:\", bareduckdb.__version__)'; then
                echo 'ERROR: bareduckdb failed to install or import'
                exit 1
              fi

              echo 'Installing nightly pandas and latest pyarrow'
              uv pip install --pre --upgrade --extra-index-url https://pypi.anaconda.org/scientific-python-nightly-wheels/simple --no-build pandas>=3.0 pyarrow

              # Re-enable sanitizer checks before running tests
              if [ '${{ matrix.sanitizer }}' = 'ASAN' ]; then
                echo 'Re-enabling leak detection for test execution'

                # Create LSAN suppression file for known library false positives
                # Note: leak: suppressions are for LeakSanitizer (LSAN), not ASAN
                # Using multiple echo commands to avoid YAML/bash quoting complexity
                {
                  echo 'leak:arrow::duration'
                  echo 'leak:arrow::time32'
                  echo 'leak:arrow::time64'
                  echo 'leak:arrow::date32'
                  echo 'leak:arrow::date64'
                  echo 'leak:arrow::timestamp'
                  echo 'leak:arrow::month_day_nano_interval'
                  echo 'leak:arrow::compute::ScalarFunction'
                  echo 'leak:arrow::compute::KernelSignature'
                  echo 'leak:arrow::compute::literal'
                  echo 'leak:arrow::compute::Initialize'
                  echo 'leak:arrow::compute::internal::RegisterScalar'
                  echo 'leak:libarrow_compute'
                  echo 'leak:logging_memory_pool'
                  echo 'leak:NpyString_new_allocator'
                  echo 'leak:PyUFunc_FromFuncAndDataAndSignatureAndIdentity'
                  echo 'leak:PyArrayIdentityHash_New'
                  echo 'leak:_datetime_dtype_metadata_clone'
                  echo 'leak:npy_alloc_cache_dim'
                  echo 'leak:PyDataMem_UserNEW'
                  echo 'leak:PyThread_allocate_lock'
                  echo 'leak:create_stdio'
                  echo 'leak:init_sys_streams'
                } > /tmp/lsan_suppressions.txt

                # ASAN_OPTIONS without suppressions (leak suppressions go in LSAN_OPTIONS)
                export ASAN_OPTIONS='allocator_may_return_null=1:halt_on_error=1:detect_leaks=1:detect_stack_use_after_return=1:check_initialization_order=1:strict_string_checks=1:detect_invalid_pointer_pairs=2:symbolize=1:fast_unwind_on_malloc=0'
                export LSAN_OPTIONS='suppressions=/tmp/lsan_suppressions.txt'
                echo "ASAN_OPTIONS: \$ASAN_OPTIONS"
                echo "LSAN_OPTIONS: \$LSAN_OPTIONS"
              elif [ '${{ matrix.sanitizer }}' = 'TSAN' ]; then
                echo 'Re-enabling halt_on_error and deadlock detection for test execution'
                # Combine CPython suppressions with bareduckdb suppressions
                if [ -f /workspace/.sanitizer-thread-suppressions.txt ]; then
                  if [ -f /tmp/combined_suppressions.txt ]; then
                    cat /workspace/.sanitizer-thread-suppressions.txt >> /tmp/combined_suppressions.txt
                  else
                    cp /workspace/.sanitizer-thread-suppressions.txt /tmp/combined_suppressions.txt
                  fi
                  export TSAN_OPTIONS='halt_on_error=1:detect_deadlocks=1:suppressions=/tmp/combined_suppressions.txt'
                  echo \"Loaded bareduckdb TSAN suppressions\"
                  echo \"TSAN_OPTIONS: \$TSAN_OPTIONS\"
                else
                  export TSAN_OPTIONS='halt_on_error=1:detect_deadlocks=1'
                  echo \"Warning: No bareduckdb suppressions file found\"
                  echo \"TSAN_OPTIONS: \$TSAN_OPTIONS\"
                fi
              fi

              echo 'Running ${{ matrix.sanitizer }} tests'

              # Function to print stack trace from core dump
              print_crash_info() {
                echo 'CRASH DETECTED'
                local exit_code=\$1
                echo \"Exit code: \$exit_code\"

                # Find core dump
                local core_file=\$(ls -t /tmp/core.* 2>/dev/null | head -1)
                if [ -n \"\$core_file\" ]; then
                  echo \"Core dump found: \$core_file\"
                  echo 'Stack trace from GDB'
                  gdb -batch -ex 'thread apply all bt' -ex 'quit' python \$core_file 2>&1 || echo 'Failed to get stack trace'
                else
                  echo 'No core dump found'
                fi
              }

              if [ '${{ matrix.sanitizer }}' = 'TSAN' ]; then
                # TSAN: Run parallel tests to expose race conditions
                set +e
                THREADS=\$(($(nproc) < 4 ? $(nproc) : 4))
                python -m pytest tests/ \
                  --parallel-threads=\$THREADS \
                  -n 0 \
                  --iterations=5 \
                  --tb=short \
                  -v \
                  -m 'not asyncio' \
                  --ignore=tests/experimental \
                  --ignore=tests/downstream \
                  2>&1 | tee /workspace/${{ matrix.sanitizer }}_output.txt
                exit_code=\$?
                if [ \$exit_code -eq 139 ] || [ \$exit_code -eq 134 ]; then
                  print_crash_info \$exit_code
                fi
                exit \$exit_code
              else
                # ASAN: Run tests sequentially without --forked
                # NOTE: --forked uses os.fork() which is incompatible with ASAN
                # in multi-threaded Python 3.14t (causes CHECK failed in __cxa_throw)
                set +e
                python -m pytest tests/ \
                  -x \
                  -n 0 \
                  --tb=short \
                  -v \
                  --ignore=tests/experimental \
                  --ignore=tests/downstream \
                  2>&1 | tee /workspace/${{ matrix.sanitizer }}_output.txt
                exit_code=\$?
                if [ \$exit_code -eq 139 ] || [ \$exit_code -eq 134 ]; then
                  print_crash_info \$exit_code
                fi
                exit \$exit_code
              fi
            "

          # Cleanup: stop and remove container
          echo "Cleaning up container: $CONTAINER_ID"
          docker stop "$CONTAINER_ID"
          docker rm "$CONTAINER_ID"

      - name: Upload ${{ matrix.sanitizer }} results
        if: always()
        uses: actions/upload-artifact@main
        with:
          name: ${{ matrix.sanitizer }}-results
          path: |
            ${{ matrix.sanitizer }}_output.txt
          retention-days: 7
